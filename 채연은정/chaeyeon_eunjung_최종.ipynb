{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ad614359",
      "metadata": {
        "id": "ad614359"
      },
      "source": [
        "## 스타트업 수집 AI agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "959ff569",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "959ff569",
        "outputId": "5555eeda-feee-459e-a1f2-52d03ef8929e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0db3b149",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0db3b149",
        "outputId": "91639664-d6f6-4cbb-e9cc-060545e70b66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangChain/LangSmith API Key가 설정되지 않았습니다. 참고: https://wikidocs.net/250954\n"
          ]
        }
      ],
      "source": [
        "from typing import Annotated, TypedDict\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.graph import END, StateGraph\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "from langchain_teddynote import logging\n",
        "logging.langsmith(\"CH16-Agentic-RAG\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bNsDZbm3iG7S",
      "metadata": {
        "id": "bNsDZbm3iG7S"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain_teddynote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4eea01a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eea01a7",
        "outputId": "d747f2c3-183a-4972-fa32-0749b916c396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20250327 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20250327 pdfplumber-0.11.6 pypdfium2-4.30.1\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n",
            "Collecting langchain_opentutorial\n",
            "  Downloading langchain_opentutorial-0.0.8-py3-none-any.whl.metadata (686 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from langchain_opentutorial) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->langchain_opentutorial) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->langchain_opentutorial) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->langchain_opentutorial) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->langchain_opentutorial) (2025.1.31)\n",
            "Downloading langchain_opentutorial-0.0.8-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: langchain_opentutorial\n",
            "Successfully installed langchain_opentutorial-0.0.8\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.4.0\n",
            "Collecting langchain_teddynote\n",
            "  Downloading langchain_teddynote-0.3.45-py3-none-any.whl.metadata (867 bytes)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (from langchain_teddynote) (0.3.23)\n",
            "Collecting langgraph (from langchain_teddynote)\n",
            "  Downloading langgraph-0.3.31-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting kiwipiepy (from langchain_teddynote)\n",
            "  Downloading kiwipiepy-0.20.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting rank_bm25 (from langchain_teddynote)\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pinecone-client[grpc] (from langchain_teddynote)\n",
            "  Downloading pinecone_client-6.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting pinecone-text (from langchain_teddynote)\n",
            "  Downloading pinecone_text-0.10.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting olefile (from langchain_teddynote)\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting pdf2image (from langchain_teddynote)\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (from langchain_teddynote) (1.75.0)\n",
            "Collecting anthropic (from langchain_teddynote)\n",
            "  Downloading anthropic-0.50.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deepl (from langchain_teddynote)\n",
            "  Downloading deepl-1.21.1-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting feedparser (from langchain_teddynote)\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting tavily-python (from langchain_teddynote)\n",
            "  Downloading tavily_python-0.5.4-py3-none-any.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.6/91.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from langchain_teddynote) (2.2.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic->langchain_teddynote) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic->langchain_teddynote) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from anthropic->langchain_teddynote) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic->langchain_teddynote) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic->langchain_teddynote) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic->langchain_teddynote) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic->langchain_teddynote) (4.13.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from deepl->langchain_teddynote) (2.32.3)\n",
            "Collecting sgmllib3k (from feedparser->langchain_teddynote)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting kiwipiepy_model<0.21,>=0.20 (from kiwipiepy->langchain_teddynote)\n",
            "  Downloading kiwipiepy_model-0.20.0.tar.gz (34.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.7/34.7 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from kiwipiepy->langchain_teddynote) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kiwipiepy->langchain_teddynote) (4.67.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain->langchain_teddynote) (0.3.52)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain->langchain_teddynote) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain->langchain_teddynote) (0.3.31)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain->langchain_teddynote) (2.0.40)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain->langchain_teddynote) (6.0.2)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph->langchain_teddynote)\n",
            "  Downloading langgraph_checkpoint-2.0.24-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt<0.2,>=0.1.8 (from langgraph->langchain_teddynote)\n",
            "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph->langchain_teddynote)\n",
            "  Downloading langgraph_sdk-0.1.63-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph->langchain_teddynote)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->langchain_teddynote) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->langchain_teddynote) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->langchain_teddynote) (2025.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pdf2image->langchain_teddynote) (11.1.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone-client[grpc]->langchain_teddynote) (2025.1.31)\n",
            "Requirement already satisfied: googleapis-common-protos>=1.66.0 in /usr/local/lib/python3.11/dist-packages (from pinecone-client[grpc]->langchain_teddynote) (1.70.0)\n",
            "Requirement already satisfied: grpcio>=1.59.0 in /usr/local/lib/python3.11/dist-packages (from pinecone-client[grpc]->langchain_teddynote) (1.71.0)\n",
            "Collecting lz4>=3.1.3 (from pinecone-client[grpc]->langchain_teddynote)\n",
            "  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client[grpc]->langchain_teddynote)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: protobuf<6.0,>=5.29 in /usr/local/lib/python3.11/dist-packages (from pinecone-client[grpc]->langchain_teddynote) (5.29.4)\n",
            "Collecting protoc-gen-openapiv2<0.0.2,>=0.0.1 (from pinecone-client[grpc]->langchain_teddynote)\n",
            "  Downloading protoc_gen_openapiv2-0.0.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone-client[grpc]->langchain_teddynote) (2.3.0)\n",
            "Collecting mmh3<5.0.0,>=4.1.0 (from pinecone-text->langchain_teddynote)\n",
            "  Downloading mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from pinecone-text->langchain_teddynote) (3.9.1)\n",
            "Collecting numpy (from kiwipiepy->langchain_teddynote)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv<2.0.0,>=1.0.1 (from pinecone-text->langchain_teddynote)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting types-requests<3.0.0,>=2.25.0 (from pinecone-text->langchain_teddynote)\n",
            "  Downloading types_requests-2.32.0.20250328-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting tiktoken>=0.5.1 (from tavily-python->langchain_teddynote)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic->langchain_teddynote) (3.10)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic->langchain_teddynote) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic->langchain_teddynote) (0.14.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain->langchain_teddynote) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain->langchain_teddynote) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain->langchain_teddynote) (24.2)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph->langchain_teddynote)\n",
            "  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph->langchain_teddynote) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain->langchain_teddynote) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain->langchain_teddynote) (0.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.9.1->pinecone-text->langchain_teddynote) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.9.1->pinecone-text->langchain_teddynote) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.9.1->pinecone-text->langchain_teddynote) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic->langchain_teddynote) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic->langchain_teddynote) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic->langchain_teddynote) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->langchain_teddynote) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->deepl->langchain_teddynote) (3.4.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain->langchain_teddynote) (3.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain->langchain_teddynote) (3.0.0)\n",
            "Downloading langchain_teddynote-0.3.45-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anthropic-0.50.0-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepl-1.21.1-py3-none-any.whl (38 kB)\n",
            "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwipiepy-0.20.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.3.31-py3-none-any.whl (145 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.2/145.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pinecone_text-0.10.0-py3-none-any.whl (22 kB)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Downloading tavily_python-0.5.4-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.24-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_sdk-0.1.63-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Downloading protoc_gen_openapiv2-0.0.1-py3-none-any.whl (7.9 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20250328-py3-none-any.whl (20 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_client-6.0.0-py3-none-any.whl (6.7 kB)\n",
            "Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: kiwipiepy_model, sgmllib3k\n",
            "  Building wheel for kiwipiepy_model (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kiwipiepy_model: filename=kiwipiepy_model-0.20.0-py3-none-any.whl size=34818026 sha256=e7f98d0a9a6f02f7f81e69526fce36eb2e42136aceae91047e0330fd5f2a8a5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/c8/52/3a539d6e9065b191fe1c215e0203dcc3e00601c0e3d3d39824\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=c6e59d73a9cccedce323f5e8eb5c6780f7209fa2f2997ff4eb643965dc4387e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
            "Successfully built kiwipiepy_model sgmllib3k\n",
            "Installing collected packages: sgmllib3k, mmh3, kiwipiepy_model, xxhash, types-requests, python-dotenv, pinecone-plugin-interface, pdf2image, ormsgpack, olefile, numpy, lz4, feedparser, tiktoken, rank_bm25, protoc-gen-openapiv2, pinecone-text, pinecone-client, kiwipiepy, deepl, tavily-python, langgraph-sdk, anthropic, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain_teddynote\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed anthropic-0.50.0 deepl-1.21.1 feedparser-6.0.11 kiwipiepy-0.20.4 kiwipiepy_model-0.20.0 langchain_teddynote-0.3.45 langgraph-0.3.31 langgraph-checkpoint-2.0.24 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.63 lz4-4.4.4 mmh3-4.1.0 numpy-1.26.4 olefile-0.47 ormsgpack-1.9.1 pdf2image-1.17.0 pinecone-client-6.0.0 pinecone-plugin-interface-0.0.7 pinecone-text-0.10.0 protoc-gen-openapiv2-0.0.1 python-dotenv-1.1.0 rank_bm25-0.2.2 sgmllib3k-1.0.0 tavily-python-0.5.4 tiktoken-0.9.0 types-requests-2.32.0.20250328 xxhash-3.5.0\n",
            "Requirement already satisfied: langchain_opentutorial in /usr/local/lib/python3.11/dist-packages (0.0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from langchain_opentutorial) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->langchain_opentutorial) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->langchain_opentutorial) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->langchain_opentutorial) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->langchain_opentutorial) (2025.1.31)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement chat_models (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for chat_models\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pdfplumber\n",
        "!pip install faiss-cpu\n",
        "!pip install langchain_opentutorial\n",
        "!pip install pypdf\n",
        "!pip install langchain_teddynote\n",
        "!pip install langchain_opentutorial\n",
        "!pip install chat_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "UfrVP4JVF_SO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfrVP4JVF_SO",
        "outputId": "8a951799-5dbb-4029-a8a6-f0e20b5f66e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.53 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.3.55)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.75.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain_openai) (0.3.31)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain_openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain_openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain_openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain_openai) (4.13.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain_openai) (2.11.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.53->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.53->langchain_openai) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.53->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.53->langchain_openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.53->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.53->langchain_openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.53->langchain_openai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.3.0)\n",
            "Downloading langchain_openai-0.3.14-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain_openai\n",
            "Successfully installed langchain_openai-0.3.14\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bad5b7ff",
      "metadata": {
        "id": "bad5b7ff"
      },
      "outputs": [],
      "source": [
        "from langchain_opentutorial.rag.pdf import PDFRetrievalChain\n",
        "from langchain_opentutorial.rag.utils import format_docs\n",
        "from langchain_teddynote.messages import messages_to_history\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c84cf65e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "c84cf65e",
        "outputId": "84c27808-dd46-4dea-d3bf-73a75dc001e8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:280: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain_opentutorial.rag.pdf import PDFRetrievalChain\n",
        "# ✅ 문서 기반 RAG 세팅\n",
        "# file_path = [\"data/KatilaSEJ12.pdf\", \"data/Startup company - Wikipedia.pdf\"]\n",
        "file_path = [\"data/Startup company.pdf\"]\n",
        "\n",
        "pdf_file = PDFRetrievalChain(file_path).create_chain()\n",
        "\n",
        "pdf_retriever = pdf_file.retriever\n",
        "pdf_chain = pdf_file.chain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d24b047",
      "metadata": {
        "id": "8d24b047"
      },
      "source": [
        "### 벡터 디비 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "aa54f30f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aa54f30f",
        "outputId": "500c5c88-28c2-4acd-bacb-80fa058411cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='a1766155-4475-4fb2-9da7-721465942c66', metadata={'source': 'data/Startup company.pdf', 'file_path': 'data/Startup company.pdf', 'page': 8, 'total_pages': 38, 'Producer': 'macOS 버전 13.4(빌드 22F66) Quartz PDFContext', 'CreationDate': \"D:20250423025232Z00'00'\", 'ModDate': \"D:20250423025232Z00'00'\"}, page_content='each of the fi ve fi rms had a different starting position the simulation. Drawing on these data, we prepared\\n(i.e., relative competitive position in an industry), 20 written cases of different teams, stratifi ed by'),\n",
              " Document(id='232beaa9-0ca1-49b0-af16-eb071f7f41cc', metadata={'source': 'data/Startup company.pdf', 'file_path': 'data/Startup company.pdf', 'page': 7, 'total_pages': 38, 'Producer': 'macOS 버전 13.4(빌드 22F66) Quartz PDFContext', 'CreationDate': \"D:20250423025232Z00'00'\", 'ModDate': \"D:20250423025232Z00'00'\"}, page_content='Sonite market) to each of the fi ve fi rms such that teams compete against other teams (i.e., not against\\nsome teams initially have more resources and better computer-simulated teams). Prior work shows that'),\n",
              " Document(id='b1230595-334e-44b6-9161-e2622b2db8e9', metadata={'source': 'data/Startup company.pdf', 'file_path': 'data/Startup company.pdf', 'page': 11, 'total_pages': 38, 'Producer': 'macOS 버전 13.4(빌드 22F66) Quartz PDFContext', 'CreationDate': \"D:20250423025232Z00'00'\", 'ModDate': \"D:20250423025232Z00'00'\"}, page_content='9\\n8\\n7\\n6\\n5\\n4\\n3\\n2\\n1\\n.d.s\\nnaeM\\nelbairaV\\n60.1\\n70.1\\nsevom\\nD&R\\nyrotarolpxE\\n1\\n15.0\\n96.0\\n43.0\\nsevom\\nD&R\\nevitatiolpxE\\n2\\n80.0\\n11.0\\n87.0\\n85.0\\nsevom\\ntekram\\nyrotarolpxE\\n3\\n11.0\\n20.0−\\n20.0−\\n26.0\\n63.0\\nsevom\\ntekram\\nevitatiolpxE\\n4\\n30.0−\\n50.0−\\n20.0−\\n90.0−\\n71.0\\n62.0\\nhtworg\\nyrtsudnI\\n5\\n51.0−\\n30.0\\n01.0\\n50.0\\n61.0\\n20.0'),\n",
              " Document(id='ee0489a5-8f6c-406e-bdb1-57c7a9b1d35f', metadata={'source': 'data/Startup company.pdf', 'file_path': 'data/Startup company.pdf', 'page': 11, 'total_pages': 38, 'Producer': 'macOS 버전 13.4(빌드 22F66) Quartz PDFContext', 'CreationDate': \"D:20250423025232Z00'00'\", 'ModDate': \"D:20250423025232Z00'00'\"}, page_content='htworg\\nyrtsudnI\\n5\\n51.0−\\n30.0\\n01.0\\n50.0\\n61.0\\n20.0\\n87.0\\nnoitacfi\\nisrevid\\ntcudorP\\n6\\n81.0\\n70.0−\\n40.0\\n21.0\\n80.0−\\n90.0\\n82.4\\n40.01\\nsevom\\nrotitepmoC\\n7\\n10.0−\\n31.0\\n20.0−\\n200.0−\\n01.0\\n28.0\\n45.0\\n22.0\\n41.0\\nytisrevid\\nevom\\nD&R\\n8\\n90.0\\n60.0\\n60.0\\n30.0−\\n10.0−\\n95.0\\n70.0\\n80.0\\n71.0\\n60.0\\nytisrevid\\nevom\\ntekraM\\n9\\n10.0\\n90.0'),\n",
              " Document(id='1b84b030-dc65-4a28-81d8-558566a3ad9f', metadata={'source': 'data/Startup company.pdf', 'file_path': 'data/Startup company.pdf', 'page': 9, 'total_pages': 38, 'Producer': 'macOS 버전 13.4(빌드 22F66) Quartz PDFContext', 'CreationDate': \"D:20250423025232Z00'00'\", 'ModDate': \"D:20250423025232Z00'00'\"}, page_content='a a\\nof products in customer segment a and PT equals variable and included all six rounds, with similar\\nthe total number of products in the market. The results.\\nCopyright © 2012 Strategic Management Society Strat. Entrepreneurship J., 6: 116–132 (2012)\\nDOI: 10.1002/sej'),\n",
              " Document(id='7393c163-d016-42ef-99cb-dbcebb90af80', metadata={'source': 'data/Startup company.pdf', 'file_path': 'data/Startup company.pdf', 'page': 14, 'total_pages': 38, 'Producer': 'macOS 버전 13.4(빌드 22F66) Quartz PDFContext', 'CreationDate': \"D:20250423025232Z00'00'\", 'ModDate': \"D:20250423025232Z00'00'\"}, page_content='their strategic peaks and could get away with strate- standards’ of competition, ‘shape customer expecta-\\ngic errors. That is, fi rms with initial advantages were tions,’ and serve as ‘market movers.’ Another suc-'),\n",
              " Document(id='e7d97d4e-2199-4147-ae8e-1e1b609641cd', metadata={'source': 'data/Startup company.pdf', 'file_path': 'data/Startup company.pdf', 'page': 7, 'total_pages': 38, 'Producer': 'macOS 버전 13.4(빌드 22F66) Quartz PDFContext', 'CreationDate': \"D:20250423025232Z00'00'\", 'ModDate': \"D:20250423025232Z00'00'\"}, page_content='lished Sonite market. This market has well- starting positions constant across all of our 32 simu-\\nestablished customer segments and relatively lation runs.\\nwell-known product features. Participants describe\\nthe market as ‘relatively stable’ and ‘mature.’ The'),\n",
              " Document(id='c31ca75c-6163-4d8f-8fa1-5d762b2fda9d', metadata={'source': 'data/Startup company.pdf', 'file_path': 'data/Startup company.pdf', 'page': 11, 'total_pages': 38, 'Producer': 'macOS 버전 13.4(빌드 22F66) Quartz PDFContext', 'CreationDate': \"D:20250423025232Z00'00'\", 'ModDate': \"D:20250423025232Z00'00'\"}, page_content='7\\n41.0\\n10.0−\\n50.0\\n01.0\\n92.0\\n18.0\\n44.0\\n51.0\\n50.0\\nytisrevid\\nevom\\nD&R\\n8\\n60.0\\n71.0\\n21.0\\n01.0\\n21.0\\n84.0\\n40.0\\n31.0\\n11.0\\n30.0\\nytisrevid\\nevom\\ntekraM\\n9\\n81.0\\n33.0\\n400.0−\\n100.0\\n11.0\\n01.0\\n25.0\\n03.0\\n63.0\\n42.0\\n21.0\\necnamrofreP\\n01'),\n",
              " Document(id='7c8dbea7-c501-4c0d-80f7-0340ae27eee4', metadata={'source': 'data/Startup company.pdf', 'file_path': 'data/Startup company.pdf', 'page': 21, 'total_pages': 38, 'Producer': 'macOS 버전 13.4(빌드 22F66) Quartz PDFContext', 'CreationDate': \"D:20250423025232Z00'00'\", 'ModDate': \"D:20250423025232Z00'00'\"}, page_content='https://en.wikipedia.org/wiki/Startup_company 5/21'),\n",
              " Document(id='f3fc42f8-1943-4696-8086-f009983197dd', metadata={'source': 'data/Startup company.pdf', 'file_path': 'data/Startup company.pdf', 'page': 31, 'total_pages': 38, 'Producer': 'macOS 버전 13.4(빌드 22F66) Quartz PDFContext', 'CreationDate': \"D:20250423025232Z00'00'\", 'ModDate': \"D:20250423025232Z00'00'\"}, page_content='25. 4. 23. 오전 10:26 Startup company - Wikipedia\\nhttps://en.wikipedia.org/wiki/Startup_company 15/21')]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search_result = pdf_retriever.invoke(\"스타트업의 기준 5개를 뽑아줘\")\n",
        "search_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74169cb3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74169cb3",
        "outputId": "14d284e8-1c0d-40ee-9e66-60eea2756565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "스타트업의 기준 5개는 다음과 같습니다:\n",
            "\n",
            "1. 혁신성 (Innovation)\n",
            "2. 성장 가능성 (Growth potential)\n",
            "3. 시장의 필요성 (Market need)\n",
            "4. 자금 조달 능력 (Funding capability)\n",
            "5. 팀의 역량 (Team capability)\n",
            "\n",
            "**Source**\n",
            "- data/Startup company - Wikipedia.pdf (page 4)\n"
          ]
        }
      ],
      "source": [
        "answer = pdf_chain.invoke(\n",
        "    {\n",
        "        \"question\":\"스타트업의 기준 5개를 뽑아줘\",\n",
        "        \"context\": search_result,\n",
        "        \"chat_history\": []\n",
        "    }\n",
        ")\n",
        "\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6353204",
      "metadata": {
        "id": "b6353204"
      },
      "source": [
        "### 1번째 에이전트 State 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ad96f76a",
      "metadata": {
        "id": "ad96f76a"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated, TypedDict, List, Optional\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class StartupInfo(TypedDict):\n",
        "    name: str\n",
        "    founder: Optional[str]\n",
        "    founder_background: Optional[str]\n",
        "    website: Optional[str]\n",
        "\n",
        "class GraphState(TypedDict, total=False):\n",
        "    question: Annotated[str, \"Question\"]\n",
        "    context: Annotated[str, \"Context\"]\n",
        "    answer: Annotated[str, \"Answer\"]\n",
        "    messages: Annotated[list, add_messages]\n",
        "    startup_list: List[StartupInfo]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "1cd3d62a",
      "metadata": {
        "id": "1cd3d62a"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "# LLM 설정\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
        "\n",
        "# Tavily 도구\n",
        "tavily_tool = TavilySearchResults(tavily_api_key=TRAVILY_SEARCH_API_KEY, k=5)\n",
        "\n",
        "# Agent 초기화\n",
        "agent_executor = initialize_agent(\n",
        "    tools=[Tool(name=\"tavily_search\", func=tavily_tool.run, description=\"광고 AI 스타트업 관련 웹 검색\")],\n",
        "    llm=llm,\n",
        "    agent_type=\"zero-shot-react-description\",\n",
        "    handle_parsing_errors=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "NR0yOj8s4f5_",
      "metadata": {
        "id": "NR0yOj8s4f5_"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def extract_json_block(text: str) -> str:\n",
        "    match = re.search(r\"\\[\\s*{.*?}\\s*]\", text, re.DOTALL)\n",
        "    return match.group(0) if match else \"[]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11725e46",
      "metadata": {
        "id": "11725e46"
      },
      "outputs": [],
      "source": [
        "def retrieve_document(state: GraphState) -> GraphState:\n",
        "    latest_question = state[\"question\"]\n",
        "    retrieved_docs = pdf_retriever.invoke(latest_question)\n",
        "    formatted_docs = format_docs(retrieved_docs)\n",
        "    return {\n",
        "        **state,\n",
        "        \"context\": formatted_docs\n",
        "    }\n",
        "\n",
        "def llm_answer(state: GraphState) -> GraphState:\n",
        "    question = state[\"question\"]\n",
        "    context = state[\"context\"]\n",
        "    response = pdf_chain.invoke({\n",
        "        \"question\": question,\n",
        "        \"context\": context,\n",
        "        \"chat_history\": messages_to_history(state.get(\"messages\", []))\n",
        "    })\n",
        "    return {\n",
        "        **state,\n",
        "        \"answer\": response,\n",
        "        \"messages\": state.get(\"messages\", []) + [(\"user\", question), (\"assistant\", response)]\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "def startup_search(state: GraphState) -> GraphState:\n",
        "    criteria_text = state[\"answer\"].strip()\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    다음 기준에 따라 광고 AI 분야의 유망한 글로벌 스타트업 10개를 알려주세요:\n",
        "\n",
        "    {criteria_text}\n",
        "\n",
        "    ⚠️ 아래 형식의 **JSON 배열**만 출력하세요. 설명, 문장, 번호 매기기 없이 **순수 JSON만 출력**하세요.\n",
        "    다음 형식의 JSON만 출력하세요. 설명, 문장, 마크다운(```json)은 모두 금지합니다.\n",
        "\n",
        "    [\n",
        "      {{\n",
        "        \"name\": \"회사명\",\n",
        "        \"founder\": \"창업자 이름\",\n",
        "        \"founder_background\": \"창업자 배경 요약\",\n",
        "        \"website\": \"공식 홈페이지\"\n",
        "      }}\n",
        "    ]\n",
        "    \"\"\"\n",
        "\n",
        "    # response = agent_executor.run(prompt)\n",
        "    response = llm.invoke(prompt)\n",
        "    json_str = response.content  # ✅ 여기가 핵심!!\n",
        "\n",
        "    try:\n",
        "        json_str = extract_json_block(response)\n",
        "        startup_list = json.loads(json_str)\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ JSON 파싱 실패:\", e)\n",
        "        print(\"📄 응답 원문:\\n\", response)\n",
        "        startup_list = []\n",
        "\n",
        "    return {\n",
        "        **state,\n",
        "        \"answer\": response,\n",
        "        \"startup_list\": startup_list\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "FY08kUv5NGlQ",
      "metadata": {
        "id": "FY08kUv5NGlQ"
      },
      "outputs": [],
      "source": [
        "def startup_search(state: GraphState) -> GraphState:\n",
        "    criteria_text = state[\"answer\"].strip()\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    광고 AI 스타트업 중 유망한 10개를 추천해주세요.\n",
        "\n",
        "    다음 JSON 배열 형식만 출력하세요. 설명 문장, 마크다운(```json) 사용 금지.\n",
        "\n",
        "    [\n",
        "      {{\n",
        "        \"name\": \"회사명\",\n",
        "        \"founder\": \"창업자\",\n",
        "        \"founder_background\": \"창업자 이력\",\n",
        "        \"website\": \"공식 홈페이지\"\n",
        "      }}\n",
        "    ]\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    try:\n",
        "        json_str = response.content  # ✅ 여기!\n",
        "        startup_list = json.loads(json_str)\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ JSON 파싱 실패:\", e)\n",
        "        print(\"📄 응답 원문:\\n\", response)\n",
        "        startup_list = []\n",
        "\n",
        "    return {\n",
        "        **state,\n",
        "        \"answer\": json_str,\n",
        "        \"startup_list\": startup_list,\n",
        "        \"startup_raw\": json_str\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zv1SGHypx2zf",
      "metadata": {
        "id": "zv1SGHypx2zf"
      },
      "source": [
        "# 2번째 에이전트\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "dFoMwXj6x5xX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFoMwXj6x5xX",
        "outputId": "c3014a3e-dbc1-4487-c987-2325028cf19f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:280: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from typing import List, Dict\n",
        "import json\n",
        "\n",
        "from langchain_opentutorial.rag.pdf import PDFRetrievalChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# LLM\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
        "\n",
        "# ✅ PDF 기반 RAG 세팅\n",
        "file_path_tech = [\"data/VC-LLM_Multimodal Large Language Models Are Versatile Video Creators.pdf\"]\n",
        "pdf_file_tech = PDFRetrievalChain(file_path_tech).create_chain()\n",
        "\n",
        "pdf_retriever_tech = pdf_file_tech.retriever\n",
        "pdf_chain_tech = pdf_file_tech.chain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "rXCw1SItyzmn",
      "metadata": {
        "id": "rXCw1SItyzmn"
      },
      "outputs": [],
      "source": [
        "def tech_summary_agent(state: GraphState) -> GraphState:\n",
        "    print(\"🚀 tech_summary_agent 실행됨\")\n",
        "    startup_list = state.get(\"startup_list\", [])\n",
        "    print(\"📋 startup_list 길이:\", len(startup_list))\n",
        "    print(\"📋 startup_list 내용:\", startup_list)\n",
        "\n",
        "    tech_summary = []\n",
        "\n",
        "    for startup in startup_list:\n",
        "        name = startup.get(\"name\", \"\")\n",
        "        website = startup.get(\"website\", \"\")\n",
        "        founder_background = startup.get(\"founder_background\", \"\")\n",
        "\n",
        "        # 🔎 질문 구성\n",
        "        question = f\"\"\"\n",
        "        회사명: {name}\n",
        "        창업자 배경: {founder_background}\n",
        "        홈페이지: {website}\n",
        "\n",
        "        위 회사의 핵심 기술과 강점을 요약해주세요.\n",
        "        다음 형식의 JSON만 출력하세요. 설명, 문장, 마크다운(```json)은 모두 금지합니다.\n",
        "\n",
        "        {{\n",
        "          \"name\": \"{name}\",\n",
        "          \"core_tech\": \"핵심 기술\",\n",
        "          \"product_strength\": \"제품 또는 기술의 강점\"\n",
        "        }}\n",
        "        \"\"\"\n",
        "\n",
        "        # 🔍 context 검색\n",
        "        context = pdf_retriever_tech.invoke(question)\n",
        "\n",
        "        # 💬 LLM 응답 생성\n",
        "        try:\n",
        "            response = pdf_chain_tech.invoke({\n",
        "                \"question\": question,\n",
        "                \"context\": context,\n",
        "                \"chat_history\": []\n",
        "            })\n",
        "\n",
        "            # ✅ JSON 파싱\n",
        "            parsed = json.loads(response)\n",
        "            tech_summary.append(parsed)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ '{name}' 파싱 실패:\", e)\n",
        "            print(\"응답 원문:\", response)\n",
        "            continue\n",
        "\n",
        "    return {\n",
        "        **state,\n",
        "        \"tech_summary\": tech_summary\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "tWzvzL7YNLDj",
      "metadata": {
        "id": "tWzvzL7YNLDj"
      },
      "outputs": [],
      "source": [
        "def tech_summary_agent(state: GraphState) -> GraphState:\n",
        "    print(\"🚀 tech_summary_agent 실행됨\")\n",
        "    startup_list = state.get(\"startup_list\", [])\n",
        "    print(\"📋 startup_list 길이:\", len(startup_list))\n",
        "    print(\"📋 startup_list 내용:\", startup_list)\n",
        "\n",
        "    tech_summary = []\n",
        "\n",
        "    for startup in startup_list:\n",
        "        name = startup.get(\"name\", \"\")\n",
        "        website = startup.get(\"website\", \"\")\n",
        "        founder_background = startup.get(\"founder_background\", \"\")\n",
        "\n",
        "        # 🔎 질문 구성\n",
        "        question = f\"\"\"\n",
        "        회사명: {name}\n",
        "        창업자 배경: {founder_background}\n",
        "        홈페이지: {website}\n",
        "\n",
        "        위 회사의 핵심 기술과 강점을 요약해주세요.\n",
        "        다음 형식의 JSON만 출력하세요. 설명, 문장, 마크다운(```json)은 모두 금지합니다.\n",
        "\n",
        "        {{\n",
        "          \"name\": \"{name}\",\n",
        "          \"core_tech\": \"핵심 기술\",\n",
        "          \"product_strength\": \"제품 또는 기술의 강점\"\n",
        "        }}\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            context = pdf_retriever_tech.invoke(question)\n",
        "            response = pdf_chain_tech.invoke({\n",
        "                \"question\": question,\n",
        "                \"context\": context,\n",
        "                \"chat_history\": []\n",
        "            })\n",
        "\n",
        "            # ✅ 핵심 수정: AIMessage.content 사용\n",
        "            json_str = response.content\n",
        "            parsed = json.loads(json_str)\n",
        "\n",
        "            tech_summary.append(parsed)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ '{name}' 파싱 실패:\", e)\n",
        "            print(\"응답 원문:\", response)\n",
        "            continue\n",
        "\n",
        "    return {\n",
        "        **state,\n",
        "        \"tech_summary\": tech_summary\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BELBTcBfKIZ4",
      "metadata": {
        "id": "BELBTcBfKIZ4"
      },
      "source": [
        "# 3번째 에이전트\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "y9MQAmXKOGiM",
      "metadata": {
        "id": "y9MQAmXKOGiM"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import AIMessage\n",
        "import json\n",
        "\n",
        "def market_eval_agent(state: GraphState) -> GraphState:\n",
        "    print(\"🚀 market_eval_agent 실행됨\")\n",
        "    startup_list = state.get(\"startup_list\", [])\n",
        "    print(\"📋 startup_list 길이:\", len(startup_list))\n",
        "\n",
        "    market_eval = []\n",
        "\n",
        "    for startup in startup_list:\n",
        "        name = startup.get(\"name\", \"\")\n",
        "        industry = startup.get(\"industry\", \"광고 자동화\")  # industry 필드가 없으면 기본값\n",
        "\n",
        "        # 📌 명확한 평가 기준 반영된 프롬프트\n",
        "        question = f\"\"\"\n",
        "        '{industry}' 산업군에 속한 스타트업 중, {name}의 시장성을 평가해주세요.\n",
        "\n",
        "        📊 [시장성 평가 항목] (총점 100점)\n",
        "        아래 각 항목에 대해 {name}의 위치를 고려해 점수를 부여하세요:\n",
        "\n",
        "        1. 📈 산업 성장성 (최대 30점)\n",
        "            - 'AI 광고 제작 솔루션' 시장의 연평균 성장률(CAGR) 기반\n",
        "            - 시장이 크고 빠르게 성장하면 높은 점수\n",
        "\n",
        "        2. 📊 수요 트렌드 적합성 (최대 20점)\n",
        "            - 해당 스타트업이 타겟하는 광고/마케팅 영역의 실제 수요 증가율\n",
        "            - 퍼포먼스 마케팅/리타게팅/UGC영상 등 트렌드 적합성 기반\n",
        "\n",
        "        3. ⚔️ 경쟁 환경과 시장 포지셔닝 (최대 20점)\n",
        "            - 경쟁사 수, 진입 장벽, 점유율 등\n",
        "            - 해당 기업의 상대적 위치와 경쟁력 분석\n",
        "\n",
        "        4. 🧠 기술 차별성과 제품 완성도 (최대 20점)\n",
        "            - 생성형 AI/LLM 기반 기술의 실현 수준, 모델 성능, 제품 정교함\n",
        "\n",
        "        5. 💸 자금 유치/비즈니스 모델 (최대 10점)\n",
        "            - 실제 투자 유치 경험 or 수익화 전략\n",
        "\n",
        "        ---\n",
        "\n",
        "        ✅ 예시 점수 분포 가이드라인 (스타트업 간 분산 필수):\n",
        "        - 90점대: 산업 선도, 기술력 매우 높음, 성장세 탁월\n",
        "        - 80점대: 유망하고 경쟁력 있으나 경쟁사 대비 차별화는 보통\n",
        "        - 70점대: 시장 진입은 했으나 경쟁에서 밀릴 가능성 존재\n",
        "        - 60점대 이하: 시장 진입 초기 or 포지션 미흡\n",
        "\n",
        "        ---\n",
        "\n",
        "        📤 출력 형식 (JSON만! 설명이나 마크다운 금지):\n",
        "\n",
        "        {{\n",
        "          \"name\": \"{name}\",\n",
        "          \"market_score\": 정수 (60~95),\n",
        "          \"reason\": \"항목별 평가 결과를 종합하여 구체적으로 작성\",\n",
        "          \"rank_estimation\": \"예상 순위 (예: 1위 / 3개 중)\"\n",
        "        }}\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        try:\n",
        "            context = pdf_retriever_market.invoke(question)\n",
        "            response = pdf_chain_market.invoke({\n",
        "                \"question\": question,\n",
        "                \"context\": context,\n",
        "                \"chat_history\": []\n",
        "            })\n",
        "\n",
        "            # ✅ 응답 타입에 따라 분기 처리\n",
        "            if isinstance(response, AIMessage):\n",
        "                json_str = response.content\n",
        "            else:\n",
        "                json_str = response\n",
        "\n",
        "            parsed = json.loads(json_str)\n",
        "            market_eval.append(parsed)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ '{name}' 파싱 실패:\", e)\n",
        "            print(\"응답 원문:\", response)\n",
        "            continue\n",
        "\n",
        "    return {\n",
        "        **state,\n",
        "        \"market_eval\": market_eval\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PS_nZMHOSMJG",
      "metadata": {
        "id": "PS_nZMHOSMJG"
      },
      "source": [
        "# 4번째 에이전트\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "QHYNuEHESL-O",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHYNuEHESL-O",
        "outputId": "13bc91df-84bb-4429-806c-2db93bbfb1b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:280: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# RAG chain for scorecard PDF\n",
        "from langchain_opentutorial.rag.pdf import PDFRetrievalChain\n",
        "\n",
        "file_path_scorecard = [\"data/Scorecard Valuation Method.pdf\"]\n",
        "pdf_file_scorecard = PDFRetrievalChain(file_path_scorecard).create_chain()\n",
        "\n",
        "pdf_retriever_invest = pdf_file_scorecard.retriever\n",
        "pdf_chain_invest = pdf_file_scorecard.chain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "l-AFytggUHaT",
      "metadata": {
        "id": "l-AFytggUHaT"
      },
      "outputs": [],
      "source": [
        "def scorecard_evaluation_agent(state: GraphState) -> GraphState:\n",
        "    print(\"🚀 scorecard_evaluation_agent 실행됨\")\n",
        "    startup_list = state.get(\"startup_list\", [])\n",
        "    tech_summary = state.get(\"tech_summary\", [])\n",
        "    market_eval = state.get(\"market_eval\", [])\n",
        "\n",
        "    investment_score = []\n",
        "\n",
        "    for startup in startup_list:\n",
        "        name = startup[\"name\"]\n",
        "        summary = next((s for s in tech_summary if s[\"name\"] == name), {})\n",
        "        market = next((m for m in market_eval if m[\"name\"] == name), {})\n",
        "\n",
        "        # 📌 질문 구성: 부족한 정보는 RAG 검색 보완\n",
        "        question = f\"\"\"\n",
        "        다음 스타트업 중 '{name}'에 대한 투자 판단을 해주세요.\n",
        "\n",
        "        🔎 비교 대상 목록:\n",
        "        {name_list_str}\n",
        "\n",
        "        🔍 평가 기준은 다음과 같습니다:\n",
        "        1. 창업자 전문성, 커뮤니케이션, 실행력 (30%)\n",
        "        2. 시장성: 시장 크기와 성장 가능성 (25%)\n",
        "        3. 제품/기술력: 독창성, 구현 가능성 (15%)\n",
        "        4. 경쟁 우위: 진입장벽, 특허, 네트워크 효과 (10%)\n",
        "        5. 실적: 매출, 유저수, 계약 등 (10%)\n",
        "        6. 투자조건: 밸류에이션, 지분율 등 (10%)\n",
        "\n",
        "        다른 기업과 비교하여 '{name}'이 어떤 점에서 강점 또는 약점이 있는지 기반으로 점수를 차등 부여해주세요.\n",
        "\n",
        "        📤 다음 형식의 JSON만 출력하세요. 설명, 마크다운 금지:\n",
        "        {{\n",
        "          \"name\": \"{name}\",\n",
        "          \"owner\": 0~10,\n",
        "          \"market\": 0~10,\n",
        "          \"tech\": 0~10,\n",
        "          \"advantage\": 0~10,\n",
        "          \"traction\": 0~10,\n",
        "          \"deal_terms\": 0~10,\n",
        "          \"total_score\": \"가중 평균 점수 (100점 만점)\",\n",
        "          \"decision\": \"투자 유망 / 보류 / 불합격 중 선택\"\n",
        "        }}\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        try:\n",
        "            context = pdf_retriever_invest.invoke(question)\n",
        "            response = pdf_chain_invest.invoke({\n",
        "                \"question\": question,\n",
        "                \"context\": context,\n",
        "                \"chat_history\": []\n",
        "            })\n",
        "\n",
        "            # ✅ AIMessage에서 .content 추출\n",
        "            if isinstance(response, AIMessage):\n",
        "                json_str = response.content\n",
        "            else:\n",
        "                json_str = response\n",
        "\n",
        "            parsed = json.loads(json_str)\n",
        "            investment_score.append(parsed)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ '{name}' 투자 판단 실패:\", e)\n",
        "            print(\"응답 원문:\", response)\n",
        "            continue\n",
        "\n",
        "    return {\n",
        "        **state,\n",
        "        \"investment_score\": investment_score\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dm5DhWu_cE0j",
      "metadata": {
        "id": "dm5DhWu_cE0j"
      },
      "source": [
        "# 5번째 에이전트\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "id": "VUB1Eq3zcSBQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUB1Eq3zcSBQ",
        "outputId": "c58a237a-1264-4bf8-8d79-489a6b3ff8fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m235.5/244.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ],
      "source": [
        "pip install python-docx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "id": "bixIrHWZcEou",
      "metadata": {
        "id": "bixIrHWZcEou"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "from docx import Document\n",
        "from typing import Optional\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"Remove unsupported characters for .docx (like emojis).\"\"\"\n",
        "    return text.encode(\"latin-1\", errors=\"ignore\").decode(\"latin-1\")\n",
        "\n",
        "@tool\n",
        "def report_generation_agent(\n",
        "    overview: str,\n",
        "    tech_summary: list,\n",
        "    market_eval: list,\n",
        "    investment_score: list,\n",
        "    docx_path: Optional[str] = \"startup_investment_report.docx\"\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    스타트업 분석 결과를 기반으로 PDF 형식의 투자 리포트를 작성합니다.\n",
        "\n",
        "    :param overview: 전체 분석 개요 요약\n",
        "    :param tech_summary: 기술 요약 리스트\n",
        "    :param market_eval: 시장성 평가 리스트\n",
        "    :param investment_score: 투자 판단 리스트\n",
        "    :param docx_path: 저장할 파일 경로 (기본값: startup_investment_report.docx)\n",
        "    :return: 생성된 문서 파일 경로\n",
        "    \"\"\"\n",
        "    doc = Document()\n",
        "\n",
        "    # 제목\n",
        "    doc.add_heading(clean_text(\"스타트업 투자 분석 리포트\"), 0)\n",
        "\n",
        "    # 1. 개요\n",
        "    doc.add_heading(\"1. 개요\", level=1)\n",
        "    doc.add_paragraph(clean_text(overview))\n",
        "\n",
        "    # 2. 스타트업 분석\n",
        "    doc.add_heading(\"2. 스타트업 기술 분석\", level=1)\n",
        "    for item in tech_summary:\n",
        "        doc.add_heading(clean_text(item[\"name\"]), level=2)\n",
        "        doc.add_paragraph(f\"핵심 기술: {clean_text(item.get('core_tech', 'N/A'))}\")\n",
        "        doc.add_paragraph(f\"기술 강점: {clean_text(item.get('product_strength', 'N/A'))}\")\n",
        "\n",
        "    # 3. 시장성 평가\n",
        "    doc.add_heading(\"3. 관련 기업 시장성 요약\", level=1)\n",
        "    for item in market_eval:\n",
        "        doc.add_heading(clean_text(item[\"name\"]), level=2)\n",
        "        doc.add_paragraph(f\"시장성 점수: {item.get('market_score', 'N/A')}점\")\n",
        "        doc.add_paragraph(f\"평가 근거: {clean_text(item.get('reason', ''))}\")\n",
        "\n",
        "    # 4. 기업별 투자 평가\n",
        "    doc.add_heading(\"4. 기업별 투자 판단\", level=1)\n",
        "    for item in investment_score:\n",
        "        doc.add_heading(clean_text(item[\"name\"]), level=2)\n",
        "        doc.add_paragraph(f\"창업자: {item.get('owner', 'N/A')}점\")\n",
        "        doc.add_paragraph(f\"시장성: {item.get('market', 'N/A')}점\")\n",
        "        doc.add_paragraph(f\"기술력: {item.get('tech', 'N/A')}점\")\n",
        "        doc.add_paragraph(f\"경쟁 우위: {item.get('advantage', 'N/A')}점\")\n",
        "        doc.add_paragraph(f\"실적: {item.get('traction', 'N/A')}점\")\n",
        "        doc.add_paragraph(f\"투자조건: {item.get('deal_terms', 'N/A')}점\")\n",
        "        doc.add_paragraph(f\"총점: {item.get('total_score', 'N/A')}점\")\n",
        "        doc.add_paragraph(f\"판단 결과: {clean_text(item.get('decision', ''))}\")\n",
        "\n",
        "    # 저장\n",
        "    doc.save(docx_path)\n",
        "    return docx_path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56dd877e",
      "metadata": {
        "id": "56dd877e"
      },
      "source": [
        "# Langraph workflow 구성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "id": "e6f28416",
      "metadata": {
        "id": "e6f28416"
      },
      "outputs": [],
      "source": [
        "# from langgraph.graph import StateGraph, END\n",
        "\n",
        "# graph = StateGraph(GraphState)\n",
        "\n",
        "# graph.add_node(\"retrieve\", retrieve_document)\n",
        "# graph.add_node(\"llm_answer\", llm_answer)\n",
        "# graph.add_node(\"startup_search\", startup_search)\n",
        "\n",
        "# graph.set_entry_point(\"retrieve\")\n",
        "# graph.add_edge(\"retrieve\", \"llm_answer\")\n",
        "# graph.add_edge(\"llm_answer\", \"startup_search\")\n",
        "\n",
        "\n",
        "# # 2번째 에이전트\n",
        "# graph.add_node(\"tech_summary\", tech_summary_agent)\n",
        "# graph.add_edge(\"startup_search\", \"tech_summary\")\n",
        "# # graph.add_edge(\"tech_summary\", END)\n",
        "\n",
        "# # 3번째 에이전트\n",
        "# graph.add_node(\"market_eval\", market_eval_agent)\n",
        "# graph.add_edge(\"tech_summary\", \"market_eval\")\n",
        "# graph.add_edge(\"market_eval\", END)\n",
        "\n",
        "\n",
        "# # 4번째 에이전트\n",
        "# graph.add_node(\"investment_judgement\", scorecard_evaluation_agent)\n",
        "# graph.add_edge(\"market_eval\", \"investment_judgement\")\n",
        "\n",
        "# # 🔚 최종 종료 지점 설정\n",
        "# graph.add_edge(\"investment_judgement\", END)\n",
        "\n",
        "# app = graph.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "tG9X0g15cfQx",
      "metadata": {
        "id": "tG9X0g15cfQx"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "graph = StateGraph(GraphState)\n",
        "\n",
        "# 🧾 1. 입력 기반 문서 검색\n",
        "graph.add_node(\"retrieve\", retrieve_document)\n",
        "\n",
        "# 🧠 2. LLM 기반 질의 응답 (기준 도출)\n",
        "graph.add_node(\"llm_answer\", llm_answer)\n",
        "\n",
        "# 🔍 3. 스타트업 탐색\n",
        "graph.add_node(\"startup_search\", startup_search)\n",
        "\n",
        "# 🧬 4. 기술 요약\n",
        "graph.add_node(\"tech_summary\", tech_summary_agent)\n",
        "\n",
        "# 📊 5. 시장성 평가\n",
        "graph.add_node(\"market_eval\", market_eval_agent)\n",
        "\n",
        "# 💹 6. 투자 판단\n",
        "graph.add_node(\"investment_judgement\", scorecard_evaluation_agent)\n",
        "\n",
        "# 📄 7. PDF 보고서 생성\n",
        "graph.add_node(\"report_generation\", report_generation_agent)\n",
        "\n",
        "# 📌 그래프 흐름 설정\n",
        "graph.set_entry_point(\"retrieve\")\n",
        "\n",
        "graph.add_edge(\"retrieve\", \"llm_answer\")\n",
        "graph.add_edge(\"llm_answer\", \"startup_search\")\n",
        "graph.add_edge(\"startup_search\", \"tech_summary\")\n",
        "graph.add_edge(\"tech_summary\", \"market_eval\")\n",
        "graph.add_edge(\"market_eval\", \"investment_judgement\")\n",
        "graph.add_edge(\"investment_judgement\", \"report_generation\")\n",
        "\n",
        "# 🔚 종료 지점\n",
        "graph.add_edge(\"report_generation\", END)\n",
        "\n",
        "# 🔧 그래프 컴파일\n",
        "app = graph.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e228c961",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e228c961",
        "outputId": "fcbd00a4-5c73-4439-c401-9f9a0ed904d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mllm_answer\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "스타트업의 기준 5개는 다음과 같습니다:\n",
            "1. 혁신성: 새로운 아이디어나 기술을 기반으로 함.\n",
            "2. 성장 가능성: 시장에서의 확장 가능성이 높음.\n",
            "3. 자금 조달: 외부 투자 유치 가능성이 있음.\n",
            "4. 리스크: 높은 불확실성과 리스크를 동반함.\n",
            "5. 팀 구성: 전문성과 경험을 갖춘 팀이 필요함.\n",
            "\n",
            "AI 기반 광고 제작 솔루션 글로벌 스타트업 10개는 다음과 같습니다:\n",
            "1. Adext\n",
            "2. Albert\n",
            "3. Phrasee\n",
            "4. Persado\n",
            "5. Copy.ai\n",
            "6. Jasper\n",
            "7. Adgorithms\n",
            "8. Wordsmith\n",
            "9. Zeta Global\n",
            "10. AdRoll\n",
            "\n",
            "**Source**\n",
            "- data/Startup company.pdf (page 26)\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mstartup_search\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "[\n",
            "  {\n",
            "    \"name\": \"AdCreative.ai\",\n",
            "    \"founder\": \"Tomasz Kwiatkowski\",\n",
            "    \"founder_background\": \"Serial entrepreneur with a background in digital marketing\",\n",
            "    \"website\": \"https://www.adcreative.ai\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Pattern89\",\n",
            "    \"founder\": \"R. J. Talyor\",\n",
            "    \"founder_background\": \"Experienced in marketing technology and SaaS\",\n",
            "    \"website\": \"https://www.pattern89.com\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Albert Technologies\",\n",
            "    \"founder\": \"Or Shani\",\n",
            "    \"founder_background\": \"Background in technology and AI-driven marketing solutions\",\n",
            "    \"website\": \"https://www.albert.ai\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Cortex\",\n",
            "    \"founder\": \"Brennan White\",\n",
            "    \"founder_background\": \"Expert in content marketing and AI technology\",\n",
            "    \"website\": \"https://www.meetcortex.com\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Zeta Global\",\n",
            "    \"founder\": \"David A. Steinberg\",\n",
            "    \"founder_background\": \"Entrepreneur with extensive experience in marketing and technology\",\n",
            "    \"website\": \"https://www.zetaglobal.com\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Persado\",\n",
            "    \"founder\": \"Alex Vratskides\",\n",
            "    \"founder_background\": \"Background in AI and marketing technology\",\n",
            "    \"website\": \"https://www.persado.com\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Vidooly\",\n",
            "    \"founder\": \"Subrat Kar\",\n",
            "    \"founder_background\": \"Expert in video marketing and analytics\",\n",
            "    \"website\": \"https://www.vidooly.com\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Adthena\",\n",
            "    \"founder\": \"Ian O'Rourke\",\n",
            "    \"founder_background\": \"Background in competitive intelligence and search marketing\",\n",
            "    \"website\": \"https://www.adthena.com\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Madgicx\",\n",
            "    \"founder\": \"Yehoshua Coren\",\n",
            "    \"founder_background\": \"Digital marketing expert with a focus on analytics\",\n",
            "    \"website\": \"https://www.madgicx.com\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"NeuralSense\",\n",
            "    \"founder\": \"Mark Drummond\",\n",
            "    \"founder_background\": \"Background in neuromarketing and consumer insights\",\n",
            "    \"website\": \"https://www.neuralsense.com\"\n",
            "  }\n",
            "]🚀 tech_summary_agent 실행됨\n",
            "📋 startup_list 길이: 10\n",
            "📋 startup_list 내용: [{'name': 'AdCreative.ai', 'founder': 'Tomasz Kwiatkowski', 'founder_background': 'Serial entrepreneur with a background in digital marketing', 'website': 'https://www.adcreative.ai'}, {'name': 'Pattern89', 'founder': 'R. J. Talyor', 'founder_background': 'Experienced in marketing technology and SaaS', 'website': 'https://www.pattern89.com'}, {'name': 'Albert Technologies', 'founder': 'Or Shani', 'founder_background': 'Background in technology and AI-driven marketing solutions', 'website': 'https://www.albert.ai'}, {'name': 'Cortex', 'founder': 'Brennan White', 'founder_background': 'Expert in content marketing and AI technology', 'website': 'https://www.meetcortex.com'}, {'name': 'Zeta Global', 'founder': 'David A. Steinberg', 'founder_background': 'Entrepreneur with extensive experience in marketing and technology', 'website': 'https://www.zetaglobal.com'}, {'name': 'Persado', 'founder': 'Alex Vratskides', 'founder_background': 'Background in AI and marketing technology', 'website': 'https://www.persado.com'}, {'name': 'Vidooly', 'founder': 'Subrat Kar', 'founder_background': 'Expert in video marketing and analytics', 'website': 'https://www.vidooly.com'}, {'name': 'Adthena', 'founder': \"Ian O'Rourke\", 'founder_background': 'Background in competitive intelligence and search marketing', 'website': 'https://www.adthena.com'}, {'name': 'Madgicx', 'founder': 'Yehoshua Coren', 'founder_background': 'Digital marketing expert with a focus on analytics', 'website': 'https://www.madgicx.com'}, {'name': 'NeuralSense', 'founder': 'Mark Drummond', 'founder_background': 'Background in neuromarketing and consumer insights', 'website': 'https://www.neuralsense.com'}]\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mtech_summary\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "{\n",
            "  \"name\": \"AdCreative.ai\",\n",
            "  \"core_tech\": \"Multi-modal Large Language Models for automated video creation\",\n",
            "  \"product_strength\": \"Automates the traditionally manual process of advertisement video creation, enhancing creative output and reducing production costs.\"\n",
            "}\n",
            "\n",
            "**Source**\n",
            "- data/VC-LLM_Multimodal Large Language Models Are Versatile Video Creators.pdf (page 1)⚠️ 'AdCreative.ai' 파싱 실패: 'str' object has no attribute 'content'\n",
            "응답 원문: {\n",
            "  \"name\": \"AdCreative.ai\",\n",
            "  \"core_tech\": \"Multi-modal Large Language Models for automated video creation\",\n",
            "  \"product_strength\": \"Automates the traditionally manual process of advertisement video creation, enhancing creative output and reducing production costs.\"\n",
            "}\n",
            "\n",
            "**Source**\n",
            "- data/VC-LLM_Multimodal Large Language Models Are Versatile Video Creators.pdf (page 1)\n",
            "{\n",
            "  \"name\": \"Pattern89\",\n",
            "  \"core_tech\": \"자동화된 광고 비디오 생성 기술\",\n",
            "  \"product_strength\": \"고품질 광고 비디오 제작의 효율성 및 사용자 맞춤형 콘텐츠 제공\"\n",
            "}\n",
            "\n",
            "**Source**\n",
            "- data/VC-LLM_Multimodal Large Language Models Are Versatile Video Creators.pdf (page 1⚠️ 'Pattern89' 파싱 실패: 'str' object has no attribute 'content'\n",
            "응답 원문: {\n",
            "  \"name\": \"Pattern89\",\n",
            "  \"core_tech\": \"자동화된 광고 비디오 생성 기술\",\n",
            "  \"product_strength\": \"고품질 광고 비디오 제작의 효율성 및 사용자 맞춤형 콘텐츠 제공\"\n",
            "}\n",
            "\n",
            "**Source**\n",
            "- data/VC-LLM_Multimodal Large Language Models Are Versatile Video Creators.pdf (page 1)\n",
            "){\n",
            "  \"name\": \"Albert Technologies\",\n",
            "  \"core_tech\": \"AI-driven marketing solutions utilizing multi-modal large language models for automated advertisement video creation.\",\n",
            "  \"product_strength\": \"High-quality short-form advertisement video generation from raw footage, enhancing natural language understanding and visual content processing.\"\n",
            "}⚠️ 'Albert Technologies' 파싱 실패: 'str' object has no attribute 'content'\n",
            "응답 원문: {\n",
            "  \"name\": \"Albert Technologies\",\n",
            "  \"core_tech\": \"AI-driven marketing solutions utilizing multi-modal large language models for automated advertisement video creation.\",\n",
            "  \"product_strength\": \"High-quality short-form advertisement video generation from raw footage, enhancing natural language understanding and visual content processing.\"\n",
            "}\n",
            "{\n",
            "  \"name\": \"Cortex\",\n",
            "  \"core_tech\": \"Multi-modal Large Language Models for automated advertisement video creation\",\n",
            "  \"product_strength\": \"High-quality short-form advertisement videos with natural language understanding and generation capabilities\"\n",
            "}\n",
            "\n",
            "**Source**\n",
            "- data/VC-LLM_Multimodal Large Language Models Are Versatile Video Creators.pdf (page 0)⚠️ 'Cortex' 파싱 실패: 'str' object has no attribute 'content'\n",
            "응답 원문: {\n",
            "  \"name\": \"Cortex\",\n",
            "  \"core_tech\": \"Multi-modal Large Language Models for automated advertisement video creation\",\n",
            "  \"product_strength\": \"High-quality short-form advertisement videos with natural language understanding and generation capabilities\"\n",
            "}\n",
            "\n",
            "**Source**\n",
            "- data/VC-LLM_Multimodal Large Language Models Are Versatile Video Creators.pdf (page 0)\n",
            "{\n",
            "  \"name\": \"Zeta Global\",\n",
            "  \"core_tech\": \"Multi-modal LLMs for automated advertisement video creation\",\n",
            "  \"product_strength\": \"High-quality video production with reduced labor intensity\"\n",
            "⚠️ 'Zeta Global' 파싱 실패: 'str' object has no attribute 'content'\n",
            "응답 원문: {\n",
            "  \"name\": \"Zeta Global\",\n",
            "  \"core_tech\": \"Multi-modal LLMs for automated advertisement video creation\",\n",
            "  \"product_strength\": \"High-quality video production with reduced labor intensity\"\n",
            "}\n",
            "}{\n",
            "  \"name\": \"Persado\",\n",
            "  \"core_tech\": \"자연어 처리 및 생성, 멀티모달 LLM을 활용한 광고 비디오 자동 생성\",\n",
            "  \"product_strength\": \"고품질 짧은 광고 비디오의 자동 생성, 시각적 콘텐츠와 텍스트의 통합 처리\"\n",
            "}⚠️ 'Persado' 파싱 실패: 'str' object has no attribute 'content'\n",
            "응답 원문: {\n",
            "  \"name\": \"Persado\",\n",
            "  \"core_tech\": \"자연어 처리 및 생성, 멀티모달 LLM을 활용한 광고 비디오 자동 생성\",\n",
            "  \"product_strength\": \"고품질 짧은 광고 비디오의 자동 생성, 시각적 콘텐츠와 텍스트의 통합 처리\"\n",
            "}\n",
            "{\n",
            "  \"name\": \"Vidooly\",\n",
            "  \"core_tech\": \"Automated advertisement video creation using multi-modal large language models (LLMs)\",\n",
            "  \"product_strength\": \"Reduces production costs and accelerates content deployment for tailored video creation\"\n",
            "}\n",
            "\n",
            "**Source**\n",
            "- data/VC-LLM_Multimodal Large Language Models Are Versatile Video Creators.pdf (page ⚠️ 'Vidooly' 파싱 실패: 'str' object has no attribute 'content'\n",
            "응답 원문: {\n",
            "  \"name\": \"Vidooly\",\n",
            "  \"core_tech\": \"Automated advertisement video creation using multi-modal large language models (LLMs)\",\n",
            "  \"product_strength\": \"Reduces production costs and accelerates content deployment for tailored video creation\"\n",
            "}\n",
            "\n",
            "**Source**\n",
            "- data/VC-LLM_Multimodal Large Language Models Are Versatile Video Creators.pdf (page 1)\n",
            "1){\n",
            "  \"name\": \"Adthena\",\n",
            "  \"core_tech\": \"경쟁 정보 분석 및 검색 마케팅 기술\",\n",
            "  \"product_strength\": \"정확한 경쟁 분석 및 광고 성과 최적화\"\n",
            "}⚠️ 'Adthena' 파싱 실패: 'str' object has no attribute 'content'\n",
            "응답 원문: {\n",
            "  \"name\": \"Adthena\",\n",
            "  \"core_tech\": \"경쟁 정보 분석 및 검색 마케팅 기술\",\n",
            "  \"product_strength\": \"정확한 경쟁 분석 및 광고 성과 최적화\"\n",
            "}\n",
            "{\n",
            "  \"name\": \"Madgicx\",\n",
            "  \"core_tech\": \"Multi-modal LLMs for automated advertisement video creation\",\n",
            "  \"product_strength\": \"High-quality video generation from raw footage, efficient script generation, and segmentation\"\n",
            "}\n",
            "\n",
            "**Source**\n",
            "- data/VC-LLM_Multimodal Large Language Models Are Versatile Video Creators.pdf (page 0)⚠️ 'Madgicx' 파싱 실패: 'str' object has no attribute 'content'\n",
            "응답 원문: {\n",
            "  \"name\": \"Madgicx\",\n",
            "  \"core_tech\": \"Multi-modal LLMs for automated advertisement video creation\",\n",
            "  \"product_strength\": \"High-quality video generation from raw footage, efficient script generation, and segmentation\"\n",
            "}\n",
            "\n",
            "**Source**\n",
            "- data/VC-LLM_Multimodal Large Language Models Are Versatile Video Creators.pdf (page 0)\n",
            "{\n",
            "  \"name\": \"NeuralSense\",\n",
            "  \"core_tech\": \"다양한 소비자 통찰력을 활용한 신경 마케팅 기술\",\n",
            "  \"product_strength\": \"고품질 짧은 광고 비디오 자동 생성\"\n",
            "}⚠️ 'NeuralSense' 파싱 실패: 'str' object has no attribute 'content'\n",
            "응답 원문: {\n",
            "  \"name\": \"NeuralSense\",\n",
            "  \"core_tech\": \"다양한 소비자 통찰력을 활용한 신경 마케팅 기술\",\n",
            "  \"product_strength\": \"고품질 짧은 광고 비디오 자동 생성\"\n",
            "}\n",
            "🚀 market_eval_agent 실행됨\n",
            "📋 startup_list 길이: 10\n",
            "\n",
            "==================================================\n",
            "🔄 Node: \u001b[1;36mmarket_eval\u001b[0m 🔄\n",
            "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
            "{\n",
            "  \"name\": \"AdCreative.ai\",\n",
            "  \"market_score\": 85,\n",
            "  \"reason\": \"1. 산업 성장성: 30점 (AI 광고 제작 솔루션 시장의 높은 CAGR). 2. 수요 트렌드 적합성: 15점 (퍼포먼스 마케팅 및 리타게팅 수요 증가). 3. 경쟁 환경과 시장 포지셔닝: 15점 (경쟁사 대비 적절한 위치). 4. 기술 차별성과 제품 완성도: 15점 (생성형 AI 기술의 높은 실현 수준). 5. 자금 유치/비즈니스 모델: 10점 (실제 투자 유치 경험 있음).\",\n",
            "  \"rank_estimation\": \"2위 / 5개 중\"\n",
            "}{\n",
            "  \"name\": \"Pattern89\",\n",
            "  \"market_score\": 85,\n",
            "  \"reason\": \"1. 산업 성장성: 25점 (AI 광고 제작 솔루션 시장의 높은 CAGR). 2. 수요 트렌드 적합성: 15점 (퍼포먼스 마케팅 및 리타게팅 수요 증가). 3. 경쟁 환경과 시장 포지셔닝: 20점 (경쟁사 대비 강력한 포지셔닝). 4. 기술 차별성과 제품 완성도: 15점 (고급 생성형 AI 기술 활용). 5. 자금 유치/비즈니스 모델: 10점 (실제 투자 유치 경험 보유).\",\n",
            "  \"rank_estimation\": \"2위 / 5개 중\"\n",
            "}{\n",
            "  \"name\": \"Albert Technologies\",\n",
            "  \"market_score\": 80,\n",
            "  \"reason\": \"1. 산업 성장성: 25점 (AI 광고 제작 솔루션 시장의 높은 CAGR). 2. 수요 트렌드 적합성: 15점 (퍼포먼스 마케팅 및 리타게팅 수요 증가). 3. 경쟁 환경과 시장 포지셔닝: 15점 (경쟁사 대비 평균적인 위치). 4. 기술 차별성과 제품 완성"
          ]
        }
      ],
      "source": [
        "## 그래프 실행\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langchain_teddynote.messages import stream_graph, random_uuid\n",
        "\n",
        "config = RunnableConfig(recursion_limit=20, configurable={\"thread_id\": random_uuid()})\n",
        "\n",
        "inputs = GraphState(\n",
        "    question=\"스타트업의 기준 5개를 뽑고, AI 기반 광고 제작 솔루션 글로벌 스타트업을 10개 뽑아줘.\",\n",
        "    messages=[]\n",
        ")\n",
        "\n",
        "stream_graph(app, inputs, config, [\"llm_answer\", \"startup_search\", \"tech_summary\", \"market_eval\", \"investment_judgement\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Vyg4_0QW1iT0",
      "metadata": {
        "id": "Vyg4_0QW1iT0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "skala-db",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
